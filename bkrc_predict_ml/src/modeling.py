import time

# ===== Data =====
import numpy as np
import pandas as pd

# ===== Modeling utils =====
from sklearn.model_selection import TimeSeriesSplit
from imblearn.over_sampling import SMOTE

# ===== PyCaret (Classification) =====
from pycaret.classification import (
    setup, compare_models, create_model, tune_model, finalize_model,
    predict_model, save_model, pull, get_config, evaluate_model
)

# ===== (Optional) External model backends used by PyCaret =====
import lightgbm as lgb
import xgboost as xgb
import catboost as cb

def split_train_test(
    df:pd.DataFrame,
    trainYm: str,
    testYm: str
):
    """
    df : ì „ì²´ ë°ì´í„°
    trainYm : í•™ìŠµ ë°ì´í„° ì‹œìž‘ì¼ìž, "YYYY-MM-DD"
    testYm : í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‹œìž‘ì¼ìž, "YYYY-MM-DD"
    """
    
    # ===== 1) ë‚ ì§œ íŒŒìƒ + í”¼ì²˜ ì„ íƒ =====
    df["MONTH_dt"] = pd.to_datetime(df["MONTH"].astype(str) + "01", format="%Y%m%d")
    df_use = df.sort_values(["COM_RGNO","MONTH_dt"]).reset_index(drop=True)
    
    # ===== 3) ê³ ì • ê¸°ê°„ ë¶„ë¦¬ =====
    train_start = pd.Timestamp(trainYm)
    train_end   = pd.Timestamp(testYm)    
    train_mask  = (df_use["MONTH_dt"] >= train_start) & (df_use["MONTH_dt"] < train_end)
    train_df    = df_use.loc[train_mask].copy()
    test_df     = df_use.loc[~train_mask].copy() 
    
    train_df = train_df.dropna()
    test_df = test_df.dropna()
    
    # ì ê²€(ì„ íƒ): ê¸°ê°„/í–‰ìˆ˜ í™•ì¸
    print(train_df["MONTH_dt"].min(), "â†’", train_df["MONTH_dt"].max(), len(train_df))
    print(test_df["MONTH_dt"].min(),  "â†’", test_df["MONTH_dt"].max(),  len(test_df))

    return train_df, test_df

def createModel(train_df,test_df,target) :
    if target == "isClosed" :
        ignore_cols = ['COM_RGNO','MONTH','BZCD','MONTH_dt','CRI_NEW']
    else : 
        ignore_cols = ['COM_RGNO','MONTH','BZCD','MONTH_dt','isClosed','CRI_NEW']
    
    sm = SMOTE(sampling_strategy='auto', k_neighbors=5)
    
    exp = setup(
        data=train_df,
        target=target,
        test_data=test_df,         # â† ìµœì¢… í‰ê°€ìš©(2022-04~12)
        session_id = 25,
        train_size=0.8,            # â† í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬ ë¹„ìœ¨ (ì˜ˆ: 80% train, 20% val)
        fold = 4,
        fold_strategy = 'stratifiedkfold',   # fold ì•ˆì—ì„œ train/valëŠ” (k-1 / k) : 1/kë¡œ ë‚˜ëˆ”
        data_split_shuffle=True,  # ì…”í”Œ O
        imputation_type="simple",  # dataìžì²´ì— NaNê°’ì´ ì—†ìŒ
        normalize=False,
        remove_multicollinearity=True,
        multicollinearity_threshold=0.75,
        fix_imbalance=True,
        fix_imbalance_method=sm,
        ignore_features=ignore_cols,
        
        # ê¸°íƒ€ì„¤ì •
        use_gpu = False , # GPU ì‚¬ìš© (CUDA ë¯¸ì§€ì› ë¹Œë“œ)
        log_plots = True, # ì¤‘ìš” ê·¸ëž˜í”„(Confusion Matrix, ROC ë“± )ë¡œê¹…
        log_data = True, # ìƒ˜í”Œ ë°ì´í„° ë¡œê¹…
        verbose=True, # ë¡œê·¸ ìµœì†Œí™”
    )

    candidates = {}
    timing_results = {}

    model_names = [
        "lr",
        "ridge",
        "xgboost",
        # "nb",
        # "lda",
        # "qda",
        # "catboost",
        # "et",
        # "rf",
        # "svm",
        # "dt",
        # "knn",
        # "gbc"
    ]
    
    print("=== ëª¨ë¸ë³„ í•™ìŠµ ì‹œìž‘ ===\n")
    
    for name in model_names:
        print(f"[{name}] í•™ìŠµ ì‹œìž‘...")
        start = time.time()
    
        try:
            if name == "lr" : 
                model = create_model(name,max_iter = 2000)
            else:
                model = create_model(name)
            
            candidates[name] = model
    
            elapsed = time.time() - start
            timing_results[name] = round(elapsed, 2)
            print(f"âœ… {name} í•™ìŠµ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {elapsed:.2f}ì´ˆ)\n")
    
        except Exception as e:
            elapsed = time.time() - start
            timing_results[name] = None
            print(f"âŒ {name} í•™ìŠµ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {elapsed:.2f}ì´ˆ)")
            print(f"   ì˜¤ë¥˜ ë©”ì‹œì§€: {str(e)}\n")
    
    print("=== ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ ===\n")
    
    # ðŸ“Š ëª¨ë¸ë³„ í•™ìŠµ ì†Œìš”ì‹œê°„ ìš”ì•½
    timing_df = pd.DataFrame(
        list(timing_results.items()),
        columns=["model", "train_time_sec"]
    )
    
    # âœ… holdout ì˜ˆì¸¡ ë° ì§€í‘œ ìˆ˜ì§‘
    holdout_metrics = []
    for name, model in candidates.items():
        _ = predict_model(model)
        met = pull().copy()
        met['model'] = name
        holdout_metrics.append(met)
    
    holdout_results = pd.concat(holdout_metrics, ignore_index=True)
    
    # âœ… ëª¨ë¸ë³„ í‰ê·  ì§€í‘œ ê³„ì‚°
    avg_metrics = (
        holdout_results
        .groupby('model')[['Accuracy', 'Recall', 'Prec.', 'F1', 'AUC']]
        .mean()
        .reset_index()
    )
    
    # âœ… ì‹œê°„ ì •ë³´ ë³‘í•©
    summary = avg_metrics.merge(timing_df, on='model', how='left')
    summary.sort_values('Recall', ascending=False, inplace=True)
    print(summary.columns)
    # âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print("\n=== ëª¨ë¸ë³„ Holdout ì„±ëŠ¥ ë° í•™ìŠµì‹œê°„ ìš”ì•½ ===")

    return candidates, summary



# 2) ê³µí†µ ê·¸ë¦¬ë“œ ì„œì¹˜ í•¨ìˆ˜
def tune_with_grid(model_name, grid, optimize="Recall", fold=4):
    print(f"\n=== [{model_name}] ê¸°ë³¸ ëª¨ë¸ ìƒì„± ===")
    base = create_model(model_name, fold=fold, verbose=False)

    print(f"=== [{model_name}] GridSearch íŠœë‹ ì‹œìž‘ ===")
    tuned = tune_model(
        base,
        optimize=optimize,
        fold=fold,
        search_library="scikit-learn",   # GridSearchCV
        search_algorithm="grid",
        custom_grid=grid,
        choose_better=True,
        verbose=False
    )

    # êµì°¨ê²€ì¦ ê²°ê³¼í‘œ
    cv_table = pull()
    print(f"=== [{model_name}] CV ê²°ê³¼ ===")
    print(cv_table.head())

    return tuned, cv_table

def gridSearchModel(trainSet,testSet) :
    target = 'isClosed'
    ignore_cols = ['COM_RGNO','MONTH','MONTH_dt']
    
    exp = setup(
        data=train_df,
        target=target,
        test_data=test_df,         # â† ìµœì¢… í‰ê°€ìš©(2022-04~12)
        session_id = 25,
        train_size=0.8,            # â† í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬ ë¹„ìœ¨ (ì˜ˆ: 80% train, 20% val)
        fold = 4,
        fold_strategy = 'kfold',   # fold ì•ˆì—ì„œ train/valëŠ” (k-1 / k) : 1/kë¡œ ë‚˜ëˆ”
        data_split_shuffle=True,  # ì…”í”Œ O
        imputation_type="simple",  # dataìžì²´ì— NaNê°’ì´ ì—†ìŒ
        normalize=False,
        remove_multicollinearity=False,
        multicollinearity_threshold=0.75,
        fix_imbalance=True,
        ignore_features=ignore_cols,
        
        # ê¸°íƒ€ì„¤ì •
        use_gpu = False , # GPU ì‚¬ìš© (CUDA ë¯¸ì§€ì› ë¹Œë“œ)
        log_plots = True, # ì¤‘ìš” ê·¸ëž˜í”„(Confusion Matrix, ROC ë“± )ë¡œê¹…
        log_data = True, # ìƒ˜í”Œ ë°ì´í„° ë¡œê¹…
        verbose=True, # ë¡œê·¸ ìµœì†Œí™”
    )

    # 1) ëª¨ë¸ë³„ ê·¸ë¦¬ë“œ ì •ì˜ (LR, XGBoostë§Œ)
    grids = {
        "lr": {  # LogisticRegression
            "C": [0.1, 1.0, 3.0, 10.0],
            "penalty": ["l2"],                  # l1ì€ solver ì œì•½
            "solver": ["lbfgs", "liblinear"],   # ë°ì´í„° íŠ¹ì„±ì— ë”°ë¼ ì„ íƒ
            "max_iter": [2000, 2000]
        },
        "xgboost": {
            "n_estimators": [300, 600, 900],
            "max_depth": [3, 5, 7],
            "learning_rate": [0.03, 0.1],
            "subsample": [0.7, 1.0],
            "colsample_bytree": [0.7, 1.0],
            "min_child_weight": [1, 5]
            # í•„ìš”ì‹œ ê·œì œí•­ë„ ì¶”ê°€ ê°€ëŠ¥: "reg_lambda": [1.0, 5.0]
        }
    }

    # 3) ë‘ ëª¨ë¸ë§Œ íŠœë‹
    opt_metric = "Recall"
    kfolds = 4
    
    tuned_models = {}
    cv_results = {}
    
    for name in ["lr", "xgboost"]:
        tuned, cv_tbl = tune_with_grid(name, grids[name], optimize=opt_metric, fold=kfolds)
        tuned_models[name] = tuned
        cv_results[name] = cv_tbl
    
    # 4) í…ŒìŠ¤íŠ¸ì…‹ ì„±ëŠ¥ ë¹„êµ (setupì— test_data ì§€ì •ë¨)
    test_scores = {}
    for name, mdl in tuned_models.items():
        print(f"\n=== [{name}] í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€ ===")
        _ = predict_model(mdl)          # test_data ê¸°ì¤€ ì„±ëŠ¥ ì‚°ì¶œ
        score_tbl = pull()
        test_scores[name] = score_tbl
        cols = [c for c in ["Model","Accuracy","AUC","Recall","Precision","F1"] if c in score_tbl.columns]
        print(score_tbl[cols])
    
    # 5) Recall ê¸°ì¤€ ìµœì¢… ëª¨ë¸ ì„ íƒ
    def get_recall(df):
        # PyCaret í‘œì—ì„œ ë‹¨ì¼ í–‰ìœ¼ë¡œ ê·€ê²°ë¨(í…ŒìŠ¤íŠ¸ì…‹). ì»¬ëŸ¼ ì¡´ìž¬ ê°€ì •.
        return float(df["Recall"].values[0]) if "Recall" in df.columns else -1.0
    
    best_name = max(test_scores.keys(), key=lambda k: get_recall(test_scores[k]))
    final_model = finalize_model(tuned_models[best_name])
    print(f"\nðŸŽ¯ ìµœì¢… ì„ íƒ ëª¨ë¸: {best_name}")